"""
train.py
Trains a YOLO26 Pose model to detect MTG card corners.

Uses 4 keypoint pose estimation (TL TR BR BL corners) instead of OBB,
so the model predicts exact quad corners for precise card extraction.

Requires the dataset generated by make_training_set.py:
    dataset/
        dataset.yaml
        images/{train,val,test}/
        labels/{train,val,test}/

Usage:
    python train.py                              # default: yolo26n-pose, 100 epochs
    python train.py --model yolo26s-pose         # larger backbone
    python train.py --epochs 200 --batch 32
    python train.py --resume --checkpoint runs/.../weights/last.pt
    python train.py --val    --checkpoint runs/.../weights/best.pt
    python train.py --export --checkpoint runs/.../weights/best.pt

See: https://docs.ultralytics.com/models/yolo26/
"""

import argparse
import time
import tempfile
from pathlib import Path
import yaml
from ultralytics import YOLO

# ── Streaming support ─────────────────────────────────────────────────────────

STREAM_EPOCH_SIZE     = 10_000  # train samples per epoch
STREAM_VAL_EPOCH_SIZE = 1000   # val samples per epoch

def _patch_trainer_for_streaming(trainer, card_root: str, bg_root: str):
    """
    Replace the trainer's build_dataset so both train and val splits use
    StreamingOBBDataset — no dataset files required at all.
    """
    from streaming_dataset import StreamingPoseDataset

    def build_dataset(self, img_path, mode="train", batch=None):
        epoch_size = STREAM_EPOCH_SIZE if mode == "train" else STREAM_VAL_EPOCH_SIZE
        return StreamingPoseDataset(
            epoch_size = epoch_size,
            card_root  = card_root,
            bg_root    = bg_root,
            data       = self.data,
            task       = "pose",
            imgsz      = self.args.imgsz,
            augment    = False,
            hyp        = self.args,
            rect       = self.args.rect,
            batch_size = batch or self.args.batch,
            cache      = False,   # never cache — images are generated on demand
        )

    trainer.__class__.build_dataset = build_dataset

def _make_streaming_yaml() -> str:
    """
    Write a minimal temporary dataset.yaml for streaming mode.

    Ultralytics validates the yaml before any callback fires, so we need a file
    that exists with valid keys.  All paths point at cwd (always exists).
    """
    cwd = str(Path.cwd().resolve())
    data = {
        "nc": 1,
        "names": ["card"],
        "kpt_shape": [4, 3],   # 4 corners, each with x y visibility
        "train": cwd,
        "val": cwd,
        "test": cwd,
    }
    tmp = tempfile.NamedTemporaryFile(
        mode="w", suffix=".yaml", prefix="stream_dataset_",
        delete=False, dir=tempfile.gettempdir()
    )
    yaml.dump(data, tmp)
    tmp.close()
    return str(Path(tmp.name).resolve())


DATASET_YAML  = "dataset/dataset.yaml"
DEFAULT_MODEL = "yolo26n-pose.pt"  # nano pose — fastest to train, good baseline

# ── Actions ───────────────────────────────────────────────────────────────────

def train(args):
    if args.resume:
        if not args.checkpoint:
            raise ValueError("--resume requires --checkpoint path/to/last.pt")
        print(f"Resuming from {args.checkpoint}")
        model = YOLO(args.checkpoint)
        model.train(resume=True)
    else:
        # Redirect Ultralytics pretrained-weight downloads to models/
        from ultralytics.utils import SETTINGS
        Path("models").mkdir(exist_ok=True)
        SETTINGS.update({"weights_dir": str(Path("models").resolve())})
        model = YOLO(args.model)

        if args.debug:
            def on_train_start(trainer):
                import numpy as np
                ds = trainer.train_loader.dataset
                orig = ds.__class__.get_image_and_label
                count = [0]
                n = args.debug_n

                def fmt_val(v):
                    if isinstance(v, np.ndarray):
                        if v.size == 0:
                            return f"ndarray shape={v.shape} dtype={v.dtype} (empty)"
                        return (f"ndarray shape={v.shape} dtype={v.dtype} "
                                f"min={float(v.min()):.4f} max={float(v.max()):.4f}")
                    return repr(v)

                def print_instances(inst):
                    from ultralytics.utils.instance import Instances
                    if not isinstance(inst, Instances):
                        print(f"  {'instances':20s}: {repr(inst)}")
                        return
                    bboxes = inst.bboxes
                    segs   = inst.segments
                    print(f"  {'instances':20s}: format={inst._bboxes.format} normalized={inst.normalized}")
                    if bboxes.size == 0:
                        print(f"    bboxes: (empty) shape={bboxes.shape}")
                    else:
                        for bi, row in enumerate(bboxes):
                            print(f"    bboxes[{bi}]: {np.array2string(row, precision=4, suppress_small=True)}")
                    if segs is None:
                        print(f"    segments: None")
                    elif segs.size == 0:
                        print(f"    segments: (empty) shape={segs.shape}")
                    else:
                        for si, seg in enumerate(segs):
                            # Show first 8 and last 8 points so we can check interpolation
                            pts = np.concatenate([seg[:8], seg[-8:]], axis=0)
                            print(f"    segments[{si}] shape={seg.shape}  "
                                  f"first8={np.array2string(seg[:8], precision=4, suppress_small=True)}  "
                                  f"last8={np.array2string(seg[-8:], precision=4, suppress_small=True)}")

                def patched(self, index):
                    result = orig(self, index)
                    if count[0] < n:
                        print(f"\n{'='*60}")
                        print(f"  [debug] sample {count[0]}  im_file: {result.get('im_file', '?')}")
                        print(f"{'='*60}")
                        for k, v in result.items():
                            if k == "instances":
                                print_instances(v)
                            else:
                                print(f"  {k:20s}: {fmt_val(v)}")
                        count[0] += 1
                    return result

                ds.__class__.get_image_and_label = patched
                print(f"[debug] hooked get_image_and_label on {ds.__class__.__name__} — printing first {n} samples")

            model.add_callback("on_train_start", on_train_start)

        if args.batch_pause > 0:
            def on_train_batch_end(trainer):
                print(f"[batch-pause] sleeping {args.batch_pause}s …", flush=True)
                time.sleep(args.batch_pause)
            model.add_callback("on_train_batch_end", on_train_batch_end)

        if args.cooldown > 0:
            def on_train_epoch_end(trainer):
                epoch = trainer.epoch + 1
                total = trainer.epochs
                if epoch < total:  # no cooldown after the final epoch
                    print(f"[cooldown] epoch {epoch}/{total} done — cooling down for {args.cooldown}s …")
                    time.sleep(args.cooldown)
                    print(f"[cooldown] resuming")
            model.add_callback("on_train_epoch_end", on_train_epoch_end)

        if args.stream:
            # Patch the trainer before training starts so the train split is
            # generated in-memory; val split still reads from dataset/dataset.yaml.
            def on_pretrain_routine_start(trainer):
                _patch_trainer_for_streaming(trainer, args.cards, args.bgs)
            model.add_callback("on_pretrain_routine_start", on_pretrain_routine_start)
            print(f"Streaming mode: {STREAM_EPOCH_SIZE} train + {STREAM_VAL_EPOCH_SIZE} val samples/epoch from "
                  f"{args.cards} + {args.bgs}")
            # Ultralytics validates the yaml path before any callback fires;
            # give it a temp yaml whose `train` key points at "." (always exists).
            data_arg = _make_streaming_yaml()
            print(f"  Using temp yaml: {data_arg}")
        else:
            data_arg = args.data

        model.train(
            data        = data_arg,
            task        = "pose",
            epochs      = args.epochs,
            batch       = args.batch,
            imgsz       = 640,
            device      = args.device,
            # Ultralytics doubles workers for val (workers * 2).  On Windows with
            # spawn, each worker process costs ~1 GB RAM and several seconds to
            # start.  In streaming mode generation is CPU-bound not I/O-bound,
            # so 2 workers (4 effective for val) is enough and starts quickly.
            workers     = 0 if args.debug else args.workers,
            # ── Optimizer ────────────────────────────────────────────────────
            # YOLO26 introduces MuSGD (SGD + Muon hybrid) as its recommended
            # optimizer — more stable convergence than AdamW for this arch.
            optimizer   = "auto",     # lets YOLO26 pick MuSGD by default
            lr0         = 1e-2,       # MuSGD works well with higher initial lr
            lrf         = 0.01,       # final lr = lr0 * lrf
            momentum    = 0.937,
            weight_decay= 5e-4,
            warmup_epochs    = 3,
            warmup_momentum  = 0.8,
            # ── Augmentation (runtime, on top of our synthetic data) ─────────
            # All augmentation is baked into the dataset by make_training_set.py;
            # disable Ultralytics runtime augmentation entirely.
            hsv_h       = 0.0,
            hsv_s       = 0.0,
            hsv_v       = 0.0,
            degrees     = 0,
            translate   = 0.0,
            scale       = 0.0,
            fliplr      = 0.0,
            mosaic      = 0.0,
            mixup       = 0.0,
            copy_paste  = 0.0,
            erasing     = 0.0,
            # ── Logging ──────────────────────────────────────────────────────
            plots       = True,
            save        = True,
            save_period = 10,         # checkpoint every N epochs
            verbose     = True,
        )

    if args.export:
        _export(args)


def validate(args):
    if not args.checkpoint:
        raise ValueError("--val requires --checkpoint path/to/best.pt")
    print(f"Validating {args.checkpoint} on {args.data}")
    model = YOLO(args.checkpoint)
    metrics = model.val(data=args.data, imgsz=640, device=args.device, plots=True)
    print(metrics)


def _export(args):
    if not args.checkpoint:
        raise ValueError("--export requires --checkpoint path/to/best.pt")
    print(f"Exporting {args.checkpoint} → ONNX")
    model = YOLO(args.checkpoint)
    model.export(format="onnx", imgsz=640, dynamic=True, simplify=True)
    print(f"ONNX saved alongside {args.checkpoint}")


# ── CLI ───────────────────────────────────────────────────────────────────────

def main():
    p = argparse.ArgumentParser(description="Train YOLO OBB on MTG card dataset")

    p.add_argument("--data",       default=DATASET_YAML,  help="Path to dataset.yaml")
    p.add_argument("--model",      default=DEFAULT_MODEL,  help="YOLO26 Pose model variant, e.g. yolo26n-pose.pt / yolo26s-pose.pt / yolo26m-pose.pt")
    p.add_argument("--epochs",     type=int,   default=100)
    p.add_argument("--batch",      type=int,   default=32,  help="Batch size (-1 = auto-detect for GPU VRAM)")
    p.add_argument("--device",     default="0",            help="cuda device index (0 = first GPU), or 'cpu'")
    p.add_argument("--workers",    type=int,   default=0)
    p.add_argument("--resume",     action="store_true",    help="Resume from latest last.pt")
    p.add_argument("--val",        action="store_true",    help="Validate only (no training)")
    p.add_argument("--export",     action="store_true",    help="Export best.pt to ONNX after training")
    p.add_argument("--checkpoint", default=None,           help="Explicit checkpoint path for --val / --export")
    p.add_argument("--stream",     action="store_true",    help="Generate samples in-memory each epoch (no dataset files needed for train split)")
    p.add_argument("--debug",      action="store_true",    help="Print get_image_and_label output for the first few samples")
    p.add_argument("--debug-n",    type=int, default=3,    dest="debug_n", help="Number of samples to print in --debug mode")
    p.add_argument("--cooldown",    type=int, default=60,     help="Seconds to sleep between epochs (GPU cooling)")
    p.add_argument("--batch-pause", type=float, default=3, dest="batch_pause", help="Seconds to sleep after each batch (throttles GPU)")
    p.add_argument("--cards",      default="data/cards/cards.lmdb",   help="Path to cards.lmdb (streaming mode)")
    p.add_argument("--bgs",        default="backgrounds.lmdb", help="Path to backgrounds.lmdb (streaming mode)")

    args = p.parse_args()

    if args.val:
        validate(args)
    else:
        train(args)
        if args.export:
            _export(args)


if __name__ == "__main__":
    main()
